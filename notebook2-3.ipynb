{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1da0484",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:12.124414Z",
     "iopub.status.busy": "2024-10-08T02:02:12.123362Z",
     "iopub.status.idle": "2024-10-08T02:02:12.916172Z",
     "shell.execute_reply": "2024-10-08T02:02:12.915034Z"
    },
    "papermill": {
     "duration": 0.803146,
     "end_time": "2024-10-08T02:02:12.918598",
     "exception": false,
     "start_time": "2024-10-08T02:02:12.115452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ASNA-hackathon/sample_submission.csv\n",
      "/kaggle/input/ASNA-hackathon/train.csv\n",
      "/kaggle/input/ASNA-hackathon/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c18bfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:12.932088Z",
     "iopub.status.busy": "2024-10-08T02:02:12.931219Z",
     "iopub.status.idle": "2024-10-08T02:02:15.692417Z",
     "shell.execute_reply": "2024-10-08T02:02:15.691443Z"
    },
    "papermill": {
     "duration": 2.770536,
     "end_time": "2024-10-08T02:02:15.694947",
     "exception": false,
     "start_time": "2024-10-08T02:02:12.924411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, auc, f1_score, roc_curve, roc_auc_score, classification_report, precision_recall_curve\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2d2822",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:15.708366Z",
     "iopub.status.busy": "2024-10-08T02:02:15.707449Z",
     "iopub.status.idle": "2024-10-08T02:02:15.783193Z",
     "shell.execute_reply": "2024-10-08T02:02:15.782136Z"
    },
    "papermill": {
     "duration": 0.085115,
     "end_time": "2024-10-08T02:02:15.785703",
     "exception": false,
     "start_time": "2024-10-08T02:02:15.700588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/ASNA-hackathon/train.csv\") #7290\n",
    "df_test = pd.read_csv(\"/kaggle/input/ASNA-hackathon/test.csv\") #1844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57587091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:15.800332Z",
     "iopub.status.busy": "2024-10-08T02:02:15.799560Z",
     "iopub.status.idle": "2024-10-08T02:02:15.816962Z",
     "shell.execute_reply": "2024-10-08T02:02:15.815943Z"
    },
    "papermill": {
     "duration": 0.02646,
     "end_time": "2024-10-08T02:02:15.819095",
     "exception": false,
     "start_time": "2024-10-08T02:02:15.792635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim over 1k\n",
       "0    6458\n",
       "1     832\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Claim over 1k'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5579e8da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:15.832187Z",
     "iopub.status.busy": "2024-10-08T02:02:15.831778Z",
     "iopub.status.idle": "2024-10-08T02:02:15.840018Z",
     "shell.execute_reply": "2024-10-08T02:02:15.838943Z"
    },
    "papermill": {
     "duration": 0.017489,
     "end_time": "2024-10-08T02:02:15.842404",
     "exception": false,
     "start_time": "2024-10-08T02:02:15.824915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/2961618207.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train['Income'].replace(0, np.nan, inplace=True)\n",
      "/tmp/ipykernel_17/2961618207.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test['Income'].replace(0, np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_train['Income'].replace(0, np.nan, inplace=True)\n",
    "df_test['Income'].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fcb1c15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:15.857083Z",
     "iopub.status.busy": "2024-10-08T02:02:15.856333Z",
     "iopub.status.idle": "2024-10-08T02:02:16.000400Z",
     "shell.execute_reply": "2024-10-08T02:02:15.999368Z"
    },
    "papermill": {
     "duration": 0.154508,
     "end_time": "2024-10-08T02:02:16.002822",
     "exception": false,
     "start_time": "2024-10-08T02:02:15.848314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for c in df_train.columns:\n",
    "    col_type = df_train[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        df_train[c] = df_train[c].astype('category')\n",
    "        \n",
    "for c in df_test.columns:\n",
    "    col_type = df_test[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        df_test[c] = df_test[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392991bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:16.016650Z",
     "iopub.status.busy": "2024-10-08T02:02:16.015920Z",
     "iopub.status.idle": "2024-10-08T02:02:16.039055Z",
     "shell.execute_reply": "2024-10-08T02:02:16.038118Z"
    },
    "papermill": {
     "duration": 0.032775,
     "end_time": "2024-10-08T02:02:16.041376",
     "exception": false,
     "start_time": "2024-10-08T02:02:16.008601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_with_missing = [col for col in df_train.columns \n",
    "                                 if df_train[col].isnull().any()]                                  \n",
    "candidate_train_predictors = df_train.drop(['CustomerID', 'Claim over 1k', 'Coverage Index', 'Education Index', 'Employment Status Index', 'Marital Status Index', 'Policy Type Index', 'Policy Index', 'Sales Channel Index', 'Vehicle Size Index'] + cols_with_missing, axis=1)\n",
    "candidate_test_predictors = df_test.drop(['CustomerID', 'Coverage Index', 'Education Index', 'Employment Status Index', 'Marital Status Index', 'Policy Type Index', 'Policy Index', 'Sales Channel Index', 'Vehicle Size Index'] + cols_with_missing, axis=1)\n",
    "\n",
    "# \"cardinality\" means the number of unique values in a column.\n",
    "# We use it as our only way to select categorical columns here. This is convenient, though\n",
    "# a little arbitrary.\n",
    "low_cardinality_cols = [cname for cname in candidate_train_predictors.columns if \n",
    "                                candidate_train_predictors[cname].nunique() < 10 and\n",
    "                                candidate_train_predictors[cname].dtype == \"object\"]\n",
    "numeric_cols = [cname for cname in candidate_train_predictors.columns if \n",
    "                                candidate_train_predictors[cname].dtype in ['int64', 'float64']]\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "train_predictors = candidate_train_predictors[my_cols]\n",
    "test_predictors = candidate_test_predictors[my_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa06fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:16.054939Z",
     "iopub.status.busy": "2024-10-08T02:02:16.054200Z",
     "iopub.status.idle": "2024-10-08T02:02:16.074707Z",
     "shell.execute_reply": "2024-10-08T02:02:16.073687Z"
    },
    "papermill": {
     "duration": 0.029703,
     "end_time": "2024-10-08T02:02:16.076916",
     "exception": false,
     "start_time": "2024-10-08T02:02:16.047213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer Lifetime Value</th>\n",
       "      <th>Months Since Last Claim</th>\n",
       "      <th>Months Since Policy Inception</th>\n",
       "      <th>Number of Open Complaints</th>\n",
       "      <th>Number of Policies</th>\n",
       "      <th>Renew Offer Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3622.69</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10610.21</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13868.02</td>\n",
       "      <td>11</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3119.69</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5999.04</td>\n",
       "      <td>45</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7285</th>\n",
       "      <td>27500.54</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7286</th>\n",
       "      <td>11750.03</td>\n",
       "      <td>9</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7287</th>\n",
       "      <td>7757.04</td>\n",
       "      <td>23</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7288</th>\n",
       "      <td>3465.16</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7289</th>\n",
       "      <td>4023.01</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7290 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer Lifetime Value  Months Since Last Claim  \\\n",
       "0                     3622.69                        4   \n",
       "1                    10610.21                       26   \n",
       "2                    13868.02                       11   \n",
       "3                     3119.69                       16   \n",
       "4                     5999.04                       45   \n",
       "...                       ...                      ...   \n",
       "7285                 27500.54                        0   \n",
       "7286                 11750.03                        9   \n",
       "7287                  7757.04                       23   \n",
       "7288                  3465.16                       19   \n",
       "7289                  4023.01                        9   \n",
       "\n",
       "      Months Since Policy Inception  Number of Open Complaints  \\\n",
       "0                               107                          3   \n",
       "1                                14                          0   \n",
       "2                                38                          0   \n",
       "3                                32                          0   \n",
       "4                               126                          0   \n",
       "...                             ...                        ...   \n",
       "7285                             28                          1   \n",
       "7286                            107                          0   \n",
       "7287                            119                          0   \n",
       "7288                             89                          0   \n",
       "7289                             72                          1   \n",
       "\n",
       "      Number of Policies  Renew Offer Type  \n",
       "0                      1                 3  \n",
       "1                      7                 1  \n",
       "2                      3                 3  \n",
       "3                      1                 2  \n",
       "4                      1                 2  \n",
       "...                  ...               ...  \n",
       "7285                   2                 1  \n",
       "7286                   2                 3  \n",
       "7287                   9                 1  \n",
       "7288                   1                 3  \n",
       "7289                   1                 2  \n",
       "\n",
       "[7290 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_training_predictors = pd.get_dummies(train_predictors)\n",
    "one_hot_encoded_training_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdafe325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:16.091378Z",
     "iopub.status.busy": "2024-10-08T02:02:16.090400Z",
     "iopub.status.idle": "2024-10-08T02:02:16.099683Z",
     "shell.execute_reply": "2024-10-08T02:02:16.098783Z"
    },
    "papermill": {
     "duration": 0.018945,
     "end_time": "2024-10-08T02:02:16.102008",
     "exception": false,
     "start_time": "2024-10-08T02:02:16.083063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df_train['Claim over 1k']\n",
    "X = one_hot_encoded_training_predictors\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea2a85",
   "metadata": {
    "papermill": {
     "duration": 0.005706,
     "end_time": "2024-10-08T02:02:16.113780",
     "exception": false,
     "start_time": "2024-10-08T02:02:16.108074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will also try LightGBM classifier and see if there are any improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "976ac4fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:16.127679Z",
     "iopub.status.busy": "2024-10-08T02:02:16.126919Z",
     "iopub.status.idle": "2024-10-08T02:02:16.138348Z",
     "shell.execute_reply": "2024-10-08T02:02:16.137285Z"
    },
    "papermill": {
     "duration": 0.020943,
     "end_time": "2024-10-08T02:02:16.140755",
     "exception": false,
     "start_time": "2024-10-08T02:02:16.119812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = df_train['Claim over 1k']\n",
    "X = candidate_train_predictors\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.20, random_state=314, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca5ea701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:16.155309Z",
     "iopub.status.busy": "2024-10-08T02:02:16.154370Z",
     "iopub.status.idle": "2024-10-08T02:02:16.651437Z",
     "shell.execute_reply": "2024-10-08T02:02:16.650427Z"
    },
    "papermill": {
     "duration": 0.507155,
     "end_time": "2024-10-08T02:02:16.654099",
     "exception": false,
     "start_time": "2024-10-08T02:02:16.146944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 666, number of negative: 5166\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 526\n",
      "[LightGBM] [Info] Number of data points in the train set: 5832, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.114198 -> initscore=-2.048564\n",
      "[LightGBM] [Info] Start training from score -2.048564\n",
      "Recall of LightGBM on test set: 0.5\n",
      "Precision of LightGBM on test set: 0.69\n",
      "F1 score of LightGBM on test set: 0.91\n",
      "ROC-AUC of LightGBM on test set: 0.7356811145510836\n",
      "PR-AUC of LightGBM on test set: 0.6242969821673525\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(objective='binary')\n",
    "lgbm.fit(train_X,train_y)\n",
    "val_y_predlgbm = lgbm.predict(val_X)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(val_y, val_y_predlgbm, pos_label=1)\n",
    "auc_roc = metrics.auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(val_y, val_y_predlgbm)\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "print(\"Recall of LightGBM on test set:\",metrics.recall_score(val_y, val_y_predlgbm,average='binary')) \n",
    "print('Precision of LightGBM on test set: {:.2f}'.format(precision_score(val_y, val_y_predlgbm))) \n",
    "print('F1 score of LightGBM on test set: {:.2f}'.format(f1_score(val_y, val_y_predlgbm, average='weighted'))) # to account for disbalance\n",
    "\n",
    "print(f\"ROC-AUC of LightGBM on test set: {auc_roc}\")\n",
    "print(f\"PR-AUC of LightGBM on test set: {auc_pr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b295b",
   "metadata": {
    "papermill": {
     "duration": 0.005939,
     "end_time": "2024-10-08T02:02:16.666456",
     "exception": false,
     "start_time": "2024-10-08T02:02:16.660517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b4d3de8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:16.680744Z",
     "iopub.status.busy": "2024-10-08T02:02:16.679977Z",
     "iopub.status.idle": "2024-10-08T02:02:16.685669Z",
     "shell.execute_reply": "2024-10-08T02:02:16.684914Z"
    },
    "papermill": {
     "duration": 0.015109,
     "end_time": "2024-10-08T02:02:16.687679",
     "exception": false,
     "start_time": "2024-10-08T02:02:16.672570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c148adff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:16.701924Z",
     "iopub.status.busy": "2024-10-08T02:02:16.701495Z",
     "iopub.status.idle": "2024-10-08T02:02:16.847914Z",
     "shell.execute_reply": "2024-10-08T02:02:16.846763Z"
    },
    "papermill": {
     "duration": 0.156458,
     "end_time": "2024-10-08T02:02:16.850434",
     "exception": false,
     "start_time": "2024-10-08T02:02:16.693976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 832, number of negative: 832\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 526\n",
      "[LightGBM] [Info] Number of data points in the train set: 1664, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Recall of LightGBM on test set: 1.0\n",
      "Precision of LightGBM on test set: 0.45\n",
      "F1 score of LightGBM on test set: 0.88\n",
      "ROC-AUC of LightGBM on test set: 0.9210526315789473\n",
      "PR-AUC of LightGBM on test set: 0.7243243243243244\n"
     ]
    }
   ],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "# fit and apply the transform\n",
    "train_X, train_y = undersample.fit_resample(X, y)\n",
    "# Build the model with the random forest regression algorithm:\n",
    "lgbm = LGBMClassifier(objective='binary')\n",
    "lgbm.fit(train_X,train_y)\n",
    "val_y_predlgbm = lgbm.predict(val_X)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(val_y, val_y_predlgbm, pos_label=1)\n",
    "auc_roc = metrics.auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(val_y, val_y_predlgbm)\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "print(\"Recall of LightGBM on test set:\",metrics.recall_score(val_y, val_y_predlgbm,average='binary')) \n",
    "print('Precision of LightGBM on test set: {:.2f}'.format(precision_score(val_y, val_y_predlgbm))) \n",
    "print('F1 score of LightGBM on test set: {:.2f}'.format(f1_score(val_y, val_y_predlgbm, average='weighted'))) # to account for disbalance\n",
    "\n",
    "print(f\"ROC-AUC of LightGBM on test set: {auc_roc}\")\n",
    "print(f\"PR-AUC of LightGBM on test set: {auc_pr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "874636ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:16.865372Z",
     "iopub.status.busy": "2024-10-08T02:02:16.864478Z",
     "iopub.status.idle": "2024-10-08T02:02:17.352641Z",
     "shell.execute_reply": "2024-10-08T02:02:17.351463Z"
    },
    "papermill": {
     "duration": 0.497946,
     "end_time": "2024-10-08T02:02:17.354923",
     "exception": false,
     "start_time": "2024-10-08T02:02:16.856977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 6458, number of negative: 6458\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 526\n",
      "[LightGBM] [Info] Number of data points in the train set: 12916, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Recall of LightGBM on test set: 1.0\n",
      "Precision of LightGBM on test set: 0.83\n",
      "F1 score of LightGBM on test set: 0.98\n",
      "ROC-AUC of LightGBM on test set: 0.9864551083591332\n",
      "PR-AUC of LightGBM on test set: 0.9129353233830846\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "# fit and apply the transform\n",
    "train_X, train_y = oversample.fit_resample(X, y)\n",
    "# Build the model with the random forest regression algorithm:\n",
    "lgbm = LGBMClassifier(objective='binary')\n",
    "lgbm.fit(train_X,train_y)\n",
    "val_y_predlgbm = lgbm.predict(val_X)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(val_y, val_y_predlgbm, pos_label=1)\n",
    "auc_roc = metrics.auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(val_y, val_y_predlgbm)\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "print(\"Recall of LightGBM on test set:\",metrics.recall_score(val_y, val_y_predlgbm,average='binary')) \n",
    "print('Precision of LightGBM on test set: {:.2f}'.format(precision_score(val_y, val_y_predlgbm))) \n",
    "print('F1 score of LightGBM on test set: {:.2f}'.format(f1_score(val_y, val_y_predlgbm, average='weighted'))) # to account for disbalance\n",
    "\n",
    "print(f\"ROC-AUC of LightGBM on test set: {auc_roc}\")\n",
    "print(f\"PR-AUC of LightGBM on test set: {auc_pr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c834471f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:17.370460Z",
     "iopub.status.busy": "2024-10-08T02:02:17.369690Z",
     "iopub.status.idle": "2024-10-08T02:02:17.404842Z",
     "shell.execute_reply": "2024-10-08T02:02:17.403770Z"
    },
    "papermill": {
     "duration": 0.045914,
     "end_time": "2024-10-08T02:02:17.407409",
     "exception": false,
     "start_time": "2024-10-08T02:02:17.361495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = lgbm.predict(candidate_test_predictors)\n",
    "output = pd.DataFrame({'CustomerID': df_test.CustomerID, 'Claim over 1k': predictions})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05ae84fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:17.422605Z",
     "iopub.status.busy": "2024-10-08T02:02:17.421845Z",
     "iopub.status.idle": "2024-10-08T02:02:17.427244Z",
     "shell.execute_reply": "2024-10-08T02:02:17.426179Z"
    },
    "papermill": {
     "duration": 0.015352,
     "end_time": "2024-10-08T02:02:17.429333",
     "exception": false,
     "start_time": "2024-10-08T02:02:17.413981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# over = RandomOverSampler(sampling_strategy=0.7)\n",
    "# train_X, train_y = over.fit_resample(X, y)\n",
    "# # define undersampling strategy\n",
    "# under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# # fit and apply the transform\n",
    "# train_X, train_y = under.fit_resample(X, y)\n",
    "# # summarize class distribution\n",
    "\n",
    "# # Build the model with the random forest regression algorithm:\n",
    "# lgbm = LGBMClassifier(objective='binary')\n",
    "# lgbm.fit(train_X, train_y)\n",
    "# val_y_predlgbm = lgbm.predict(val_X)\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(val_y, val_y_predlgbm, pos_label=1)\n",
    "# auc_roc = metrics.auc(fpr, tpr)\n",
    "# precision, recall, _ = precision_recall_curve(val_y, val_y_predlgbm)\n",
    "# auc_pr = auc(recall, precision)\n",
    "\n",
    "# print(\"Recall of LightGBM on test set:\",metrics.recall_score(val_y, val_y_predlgbm,average='binary')) \n",
    "# print('Precision of LightGBM on test set: {:.2f}'.format(precision_score(val_y, val_y_predlgbm))) \n",
    "# print('F1 score of LightGBM on test set: {:.2f}'.format(f1_score(val_y, val_y_predlgbm, average='weighted'))) # to account for disbalance\n",
    "\n",
    "# print(f\"ROC-AUC of LightGBM on test set: {auc_roc}\")\n",
    "# print(f\"PR-AUC of LightGBM on test set: {auc_pr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69167c3",
   "metadata": {
    "papermill": {
     "duration": 0.006252,
     "end_time": "2024-10-08T02:02:17.442160",
     "exception": false,
     "start_time": "2024-10-08T02:02:17.435908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d27d4d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:17.457363Z",
     "iopub.status.busy": "2024-10-08T02:02:17.456349Z",
     "iopub.status.idle": "2024-10-08T02:02:17.461231Z",
     "shell.execute_reply": "2024-10-08T02:02:17.460217Z"
    },
    "papermill": {
     "duration": 0.014784,
     "end_time": "2024-10-08T02:02:17.463404",
     "exception": false,
     "start_time": "2024-10-08T02:02:17.448620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # https://www.kaggle.com/code/mlisovyi/beware-of-categorical-features-in-lgbm\n",
    "# fit_params={\"eval_metric\" : 'auc', \n",
    "#             \"eval_set\" : [(val_X,val_y)],\n",
    "#             'eval_names': ['valid'],\n",
    "#             'feature_name': 'auto', # that's actually the default\n",
    "#             'categorical_feature': ['State', 'Response', 'Coverage', 'Education', 'Employment Status',\n",
    "#        'Gender', 'Marital Status', 'Policy Type', 'Policy', 'Sales Channel',\n",
    "#        'Vehicle Size', 'Renew Offer Type']\n",
    "#            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37fdcbc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:17.478383Z",
     "iopub.status.busy": "2024-10-08T02:02:17.477612Z",
     "iopub.status.idle": "2024-10-08T02:02:17.482742Z",
     "shell.execute_reply": "2024-10-08T02:02:17.481640Z"
    },
    "papermill": {
     "duration": 0.014983,
     "end_time": "2024-10-08T02:02:17.484978",
     "exception": false,
     "start_time": "2024-10-08T02:02:17.469995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 1000 define only the absolute maximum\n",
    "# clf = lgb.LGBMClassifier(num_leaves= 15, max_depth=-1, \n",
    "#                          random_state=314, \n",
    "#                          silent=True, \n",
    "#                          metric='None', \n",
    "#                          n_jobs=4, \n",
    "#                          n_estimators=1000,\n",
    "#                          colsample_bytree=0.9,\n",
    "#                          subsample=0.9,\n",
    "#                          learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c930792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:17.500155Z",
     "iopub.status.busy": "2024-10-08T02:02:17.499183Z",
     "iopub.status.idle": "2024-10-08T02:02:17.504384Z",
     "shell.execute_reply": "2024-10-08T02:02:17.503358Z"
    },
    "papermill": {
     "duration": 0.0151,
     "end_time": "2024-10-08T02:02:17.506527",
     "exception": false,
     "start_time": "2024-10-08T02:02:17.491427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #force larger number of max trees and smaller learning rate\n",
    "# clf.fit(train_X, train_y, **fit_params)\n",
    "\n",
    "# val_y_predlgbm = lgbm.predict(val_X)\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(val_y, val_y_predlgbm, pos_label=1)\n",
    "# auc_roc = metrics.auc(fpr, tpr)\n",
    "# precision, recall, _ = precision_recall_curve(val_y, val_y_predlgbm)\n",
    "# auc_pr = auc(recall, precision)\n",
    "\n",
    "# print(\"Recall of LightGBM on test set:\",metrics.recall_score(val_y, val_y_predlgbm,average='binary')) \n",
    "# print('Precision of LightGBM on test set: {:.2f}'.format(precision_score(val_y, val_y_predlgbm))) \n",
    "# print('F1 score of LightGBM on test set: {:.2f}'.format(f1_score(val_y, val_y_predlgbm, average='weighted'))) # to account for disbalance\n",
    "\n",
    "# print(f\"ROC-AUC of LightGBM on test set: {auc_roc}\")\n",
    "# print(f\"PR-AUC of LightGBM on test set: {auc_pr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a482e8d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-08T02:02:17.521823Z",
     "iopub.status.busy": "2024-10-08T02:02:17.520919Z",
     "iopub.status.idle": "2024-10-08T02:02:17.525412Z",
     "shell.execute_reply": "2024-10-08T02:02:17.524406Z"
    },
    "papermill": {
     "duration": 0.014449,
     "end_time": "2024-10-08T02:02:17.527563",
     "exception": false,
     "start_time": "2024-10-08T02:02:17.513114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictions = clf.predict(candidate_test_predictors)\n",
    "# output = pd.DataFrame({'CustomerID': df_test.CustomerID, 'Claim over 1k': predictions})\n",
    "# output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9539422,
     "sourceId": 84218,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.17262,
   "end_time": "2024-10-08T02:02:18.355070",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-08T02:02:09.182450",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
